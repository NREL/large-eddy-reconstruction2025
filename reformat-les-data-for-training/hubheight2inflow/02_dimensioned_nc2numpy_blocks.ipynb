{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd42a59",
   "metadata": {},
   "source": [
    "This notebook reads in netCDF inflow plane data that has been dimensioned properly, and it output time-blocks of numpy data that is organized by campaign number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d894dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import matplotlib.dates as mdates\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import scipy.interpolate as interpolate\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93212ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### User inputs\n",
    "n_tsteps = 256\n",
    "nvars_out = 5  # velocityx, velocityy, velocityz, temperature, tke\n",
    "plane_loc = '3D'\n",
    "outdir = Path(f'/scratch/orybchuk/wakedynamics/bcs-ldm/data/072415/post_processing/inflow-bc-{plane_loc}/npy_blocks{n_tsteps}')\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "downsample_time = True\n",
    "bc_out_tinterval = 1.0  # sec, the save frequency that we downsample to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3fe2b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in data\n",
    "parent_dir = Path('/scratch/orybchuk/wakedynamics/bcs-ldm/data/072415/post_processing/nc_dimensioned')\n",
    "\n",
    "bc_files = list(parent_dir.glob(f'inflow-bc-{plane_loc}*.nc'))\n",
    "bc_files.sort()\n",
    "n_campaigns = len(bc_files)\n",
    "\n",
    "# campaign_num = str(0).zfill(4)\n",
    "# ds_bc = xr.open_dataset(Path(parent_dir,f'inflow-bc{campaign_num}.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74fdf1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare to convert the files\n",
    "var_maxes = np.zeros(nvars_out)\n",
    "var_mins = np.zeros(nvars_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad17346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 11:42:43.086240 0\n",
      "2024-02-18 11:49:40.143580 10\n",
      "2024-02-18 11:57:33.326587 20\n",
      "2024-02-18 12:05:34.038573 30\n",
      "2024-02-18 12:12:14.494062 40\n",
      "2024-02-18 12:21:40.878394 50\n",
      "2024-02-18 12:29:11.380624 60\n",
      "2024-02-18 12:37:20.217679 70\n",
      "2024-02-18 12:43:59.606869 80\n",
      "2024-02-18 12:51:38.587348 90\n",
      "2024-02-18 12:59:19.677076 100\n",
      "2024-02-18 13:07:39.412737 110\n",
      "2024-02-18 13:15:32.028750 120\n",
      "2024-02-18 13:23:34.523924 130\n",
      "2024-02-18 13:30:56.829188 140\n",
      "2024-02-18 13:39:24.899674 150\n",
      "2024-02-18 13:47:11.364501 160\n",
      "2024-02-18 13:55:28.435479 170\n",
      "2024-02-18 14:03:09.257153 180\n",
      "2024-02-18 14:10:55.201411 190\n",
      "2024-02-18 14:19:14.970072 200\n",
      "2024-02-18 14:27:55.696563 210\n",
      "2024-02-18 14:35:25.316008 220\n",
      "2024-02-18 14:42:35.212492 230\n",
      "2024-02-18 14:49:56.925832 240\n",
      "2024-02-18 14:58:16.093126 250\n",
      "2024-02-18 15:06:40.036231 260\n",
      "2024-02-18 15:14:49.376145 270\n",
      "2024-02-18 15:23:37.235061 280\n",
      "2024-02-18 15:30:48.187373 290\n",
      "2024-02-18 15:38:07.431421 300\n",
      "2024-02-18 15:51:49.854395 310\n",
      "2024-02-18 15:58:50.353119 320\n",
      "2024-02-18 16:06:40.404958 330\n",
      "2024-02-18 16:13:50.353143 340\n",
      "Variable maximums: [ 15.28925506   7.40720122   7.26906726 322.20324584   3.73675291]\n",
      "Variable minimums: [-1.54859019e+00 -7.41711377e+00 -4.73665247e+00  3.17892112e+02\n",
      " -2.57892700e-01]\n"
     ]
    }
   ],
   "source": [
    "### Convert to blocked numpy files\n",
    "for icamp, fcampaign in enumerate(bc_files):  # Iterate over campaigns\n",
    "    if icamp % 10 == 0: print(datetime.now(), icamp)\n",
    "    ds_bc = xr.open_dataset(fcampaign)\n",
    "    \n",
    "    if downsample_time:  # Optionally downsample the BC data\n",
    "        bc_orig_tinterval = ds_bc['time'].values[1] - ds_bc['time'].values[0]  # sec, the original save frequency\n",
    "        assert bc_out_tinterval%bc_orig_tinterval==0.0, \"bc_out_tinterval needs to be a multiple of bc_orig_tinterval!\"\n",
    "        coarse_time = np.arange(ds_bc['time'].values[0], ds_bc['time'].values[-1], bc_out_tinterval)\n",
    "        ds_bc = ds_bc.sel(time=coarse_time)\n",
    "        \n",
    "    n_full_windows = np.floor(len(ds_bc['time']) / n_tsteps).astype(int)\n",
    "    \n",
    "    for iwind in range(n_full_windows):  # Iterate over time windows\n",
    "        ds_trim = ds_bc.isel(x=0, time=slice(iwind*n_tsteps, (iwind+1)*n_tsteps))\n",
    "\n",
    "        \n",
    "        ### ----- Save out data -----\n",
    "        arr_out = np.zeros((nvars_out, n_tsteps, len(ds_bc['y']), len(ds_bc['z'])))\n",
    "        arr_out[0,:,:,:] = ds_trim['velocityx'].values\n",
    "        arr_out[1,:,:,:] = ds_trim['velocityy'].values\n",
    "        arr_out[2,:,:,:] = ds_trim['velocityz'].values\n",
    "        arr_out[3,:,:,:] = ds_trim['temperature'].values\n",
    "        arr_out[4,:,:,:] = ds_trim['tke'].values\n",
    "        \n",
    "        np.save(Path(outdir, f'{str(icamp).zfill(4)}_{str(iwind).zfill(3)}.npy'), arr_out)\n",
    "        \n",
    "        ### ----- Update statistics -----\n",
    "        if icamp == 0:\n",
    "            for j in range(nvars_out):\n",
    "                var_maxes[j] = arr_out[j,:,:,:].max()\n",
    "                var_mins[j] = arr_out[j,:,:,:].min()\n",
    "        else:\n",
    "            for j in range(nvars_out):\n",
    "                var_maxes[j] = max(var_maxes[j], arr_out[j,:,:,:].max())\n",
    "                var_mins[j] = min(var_mins[j], arr_out[j,:,:,:].min())\n",
    "                \n",
    "## Save statistics\n",
    "with open(Path(outdir, \"stats.txt\"), 'w') as fstats:\n",
    "    for i in range(nvars_out):\n",
    "        fstats.write(f\"Variable number {i} max: {var_maxes[i]}\\n\")\n",
    "        fstats.write(f\"Variable number {i} min: {var_mins[i]}\\n\")\n",
    "    \n",
    "print(\"Variable maximums:\", var_maxes)\n",
    "print(\"Variable minimums:\", var_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d1f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daskenv202404",
   "language": "python",
   "name": "daskenv202404"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
